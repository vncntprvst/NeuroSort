{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from SpikeSorting import params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_templates(channels, waveforms, spike_clusters, unique_clusters):\n",
    "    \"\"\"\n",
    "    Create average waveform templates for each cluster.\n",
    "    \n",
    "    Return: [n_clusters, n_samples, n_channels] \n",
    "    \"\"\"\n",
    "    n_clusters = len(unique_clusters)\n",
    "    n_samples = waveforms.shape[1]\n",
    "    # Estimate number of channels from waveform data\n",
    "    n_channels = len(np.unique([np.argmax(np.abs(waveforms[i])) for i in range(len(waveforms))]))\n",
    "    \n",
    "    templates = np.zeros((n_clusters, n_samples, n_channels))\n",
    "    \n",
    "    for i, cluster_id in enumerate(unique_clusters):\n",
    "        cluster_mask = (spike_clusters == cluster_id)\n",
    "        cluster_waveforms = waveforms[cluster_mask]\n",
    "        # Use the first channel where this cluster appears as main channel\n",
    "        main_channel = channels[cluster_mask][0]\n",
    "        \n",
    "        if len(cluster_waveforms) > 0:\n",
    "            mean_waveform = np.mean(cluster_waveforms, axis=0)\n",
    "            templates[i, :, main_channel] = mean_waveform\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuropixels_channel_positions(all_channels_positions, channel_map):\n",
    "    \"\"\"\n",
    "    Extract positions for valid channels from full probe layout.\n",
    "    \n",
    "    Args:\n",
    "        all_channels_positions: Complete probe layout [n_total_channels, 2]\n",
    "        channel_map: Actual valid channel ID array\n",
    "    \"\"\"\n",
    "    valid_positions = []\n",
    "    for channel_id in channel_map:\n",
    "        if 0 <= channel_id < len(all_channels_positions):\n",
    "            valid_positions.append(all_channels_positions[channel_id])\n",
    "        else:\n",
    "            print(f\"Warning: channel {channel_id} out of range, use default location\")\n",
    "            valid_positions.append([0, 0])\n",
    "    \n",
    "    return np.array(valid_positions, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc10c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_neuropixels_layout(n_channels):\n",
    "    \"\"\"\n",
    "    Create standard Neuropixels 1.0 channel layout.\n",
    "    \n",
    "    MODIFY this function for different electrode geometries:\n",
    "    - Adjust vertical_spacing, horizontal_spacing, row_offset for other probes\n",
    "    - Change the layout pattern for non-Neuropixels probes\n",
    "    \n",
    "    Geometry:\n",
    "    - Two staggered columns\n",
    "    - Vertical spacing: 20µm\n",
    "    - Horizontal spacing: 32µm \n",
    "    - Horizontal offset between adjacent rows: 16µm\n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    \n",
    "    # ADJUST these parameters for different probe types\n",
    "    vertical_spacing = 20    # µm between rows\n",
    "    horizontal_spacing = 32  # µm between columns  \n",
    "    row_offset = 16          # µm horizontal shift for alternating rows\n",
    "    \n",
    "    for channel_id in range(n_channels):\n",
    "        row = channel_id // 2\n",
    "        col = channel_id % 2\n",
    "        \n",
    "        x = col * horizontal_spacing  \n",
    "        y = row * vertical_spacing  \n",
    "        \n",
    "        # Stagger alternating rows\n",
    "        if row % 2 == 1:\n",
    "            x += row_offset\n",
    "        \n",
    "        positions.append([x, y])\n",
    "    \n",
    "    return np.array(positions, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e02836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_file(output_dir, n_channels, sample_rate):\n",
    "    \"\"\"\n",
    "    Create params.py configuration file for Phy.\n",
    "    \n",
    "    MODIFY these parameters according to your data:\n",
    "    - dat_path: Path to raw binary data file (if available)\n",
    "    - dtype: Data type of raw recording ('int16', 'float32', etc.)\n",
    "    - sample_rate: Actual sampling rate of your recording\n",
    "    \"\"\"\n",
    "    params_content = f'''\n",
    "    dat_path = '/spikesorting/neuropixel/continuous.dat'  # MODIFY: Path to raw binary data\n",
    "    n_channels_dat = {n_channels}\n",
    "    dtype = 'int16'  # MODIFY: Change if your raw data uses different data type\n",
    "    sample_rate = {sample_rate}\n",
    "    hp_filtered = False\n",
    "    '''\n",
    "    with open(os.path.join(output_dir, 'params.py'), 'w') as f:\n",
    "        f.write(params_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_groups(output_dir, unique_clusters):\n",
    "    \"\"\"\n",
    "    Create initial cluster_group.tsv file.\n",
    "    \n",
    "    All clusters are initially marked as 'unsorted'.\n",
    "    After manual curation in Phy, this will be updated to:\n",
    "    'good', 'mua' (multi-unit), 'noise', etc.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    with open(os.path.join(output_dir, 'cluster_group.tsv'), 'w', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['cluster_id', 'group'])\n",
    "        for cluster_id in unique_clusters:\n",
    "            writer.writerow([cluster_id, 'unsorted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca809a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_convert(h5_file_path, output_dir='for_phy', n_channels=384, sample_rate=30000.0):\n",
    "    \"\"\"\n",
    "    Convert custom H5 spike sorting results to Phy-compatible format.\n",
    "    \n",
    "    Args:\n",
    "        h5_file_path: Path to input H5 file containing spike data\n",
    "        output_dir: Output directory for Phy files\n",
    "        n_channels: Total number of channels in the recording system\n",
    "                   (MODIFY this if using different probe type)\n",
    "        sample_rate: Sampling rate in Hz\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    group_name = 'spikeWindow_' + str(params.get('windowForTrain'))\n",
    "    seed_name = f'seed_{params.get('seed')}'\n",
    "\n",
    "    with h5py.File(h5_file_path, 'r') as f:\n",
    "        windowInfo = f[group_name]\n",
    "        spike_times = windowInfo['time'][:] \n",
    "        channel_map = windowInfo['electrode'][:]   \n",
    "        waveforms = windowInfo['waveform'][:]         \n",
    "                  \n",
    "        sortInfo = windowInfo['sortInfo']\n",
    "        seedInfo = sortInfo[seed_name]\n",
    "        spike_clusters = seedInfo['pre_label'][:]      \n",
    "        \n",
    "        # Filter out noise clusters (cluster ID <= 0)\n",
    "        indices_units = np.where(spike_clusters > 0)[0]\n",
    "        units_c = channel_map[indices_units]\n",
    "        units_l = spike_clusters[indices_units]\n",
    "        units_t = spike_times[indices_units]\n",
    "        units_w = waveforms[indices_units]\n",
    "\n",
    "        # Save core spike data files\n",
    "        np.save(f'{output_dir}/spike_times.npy', units_t.astype(np.int64))\n",
    "        np.save(f'{output_dir}/spike_clusters.npy', units_l.astype(np.int32))\n",
    "\n",
    "        # Create channel mapping - only include channels that actually have spikes\n",
    "        unique_channels = np.unique(units_c)\n",
    "        channel_map = unique_channels.astype(np.int32)\n",
    "        np.save(os.path.join(output_dir, 'channel_map.npy'), channel_map)\n",
    "\n",
    "        # ADJUST electrode geometry here for different probes\n",
    "        full_layout = create_full_neuropixels_layout(n_channels)\n",
    "        channel_positions = create_neuropixels_channel_positions(full_layout, channel_map)\n",
    "        np.save(os.path.join(output_dir, 'channel_positions.npy'), channel_positions)\n",
    "\n",
    "        # Create template waveforms for each cluster\n",
    "        unique_clusters = np.unique(units_l)\n",
    "        templates = create_templates(units_c, units_w, units_l, unique_clusters)\n",
    "        np.save(os.path.join(output_dir, 'templates.npy'), templates.astype(np.float32))\n",
    "\n",
    "        # Create configuration file\n",
    "        create_params_file(output_dir, n_channels, sample_rate)\n",
    "\n",
    "        # Create initial cluster groups (all unsorted)\n",
    "        create_cluster_groups(output_dir, unique_clusters) \n",
    "    \n",
    "    print(f\"Convert successfully! The files are saved in Dir:{output_dir}.\\n Use: cd {output_dir} && phy template-gui params.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    quick_convert(\n",
    "            \"/spikesorting/neuropixel/results/spikeInfo.h5\", # MODIFY for .h5 sorting results\n",
    "            output_dir='for_phy', \n",
    "            n_channels=384,  # MODIFY for different probe types\n",
    "            sample_rate=30000.0  # MODIFY to match your recording\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
